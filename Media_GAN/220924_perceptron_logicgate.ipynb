{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxiUPYB7Kt8c1BdvR7O0FS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"86VHkatmZsAY"},"outputs":[],"source":["#220924"]},{"cell_type":"markdown","source":["퍼셉트론과 논리회로\n","- ANN ->hidden layer 발견-> S(shallow:얕은)NN -> D(Deep)NN\n","\n","- 퍼셉트론\n"," - 단일계층 퍼셉트론: 은닉층이 없음(최초 퍼셉트론)\n","   - FNN(피드포워드 신경망): 가장 단순(은닉층X)\n","   - AND, NAND, OR 연산 등 선형분리 가능한 문제해결에만 사용\n","  - 원리: 각 노드의 입력값 X 가중치 의 합(X1*W1 + X2*W2 +...)** 을 StepFunction(계단함수)를 거친다.\n","  - 활성화함수 >>> **결과값이 경계(임계값=세타(θ))를 넘는지(세타보다 큰지 작은지 비교)하여 0(F),1(T) 값을 반환<br>\n","  - 활성화함수 >>> 계단함수(단층퍼셉트론), 시그모이드함수(다층퍼셉트론)\n","\n","- 논리회로(logic gate)\n"," - AND(논리곱), NAND, OR(논리합)\n","   - b + W1X1 + W2X2 > 0 → 1\n","     otherwise → 0\n","     0 보다 클때만 활성화되어 '1'반환<br>\n","     (뉴런에 전기가 통한다하여 활성화함수라고 함)\n","   - (0,0),(1,0),(0,1),(1,1) 대입했을 때 각 AND, NAND, OR 를 만족시키는 w(가중치)와 b(편향)값에 따라 활성화여부 결정\n","   - '학습'이란 적절한 매개변수 값(w, b)을 정하는 작업"],"metadata":{"id":"9DTBlIaGaMsL"}},{"cell_type":"code","source":["#220930"],"metadata":{"id":"5Be54M9sldxc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MLP: 입력층, 은닉층, 출력층 적어도 3개층 이상의 퍼셉트론 ( step function, sigmoid, ReLU 등 비선형 함수를 Activation function으로 사용)\n","역전파(back Propagation)을 통해 발전\n","\n","*** A = X*W+b<br>\n","X = (x1,x2)<br>\n","A = (a1, a2, a3)<br>\n","b = (b1, b2, b3)<br>\n","w = (w11, w21, w31<br>\n","     w12, w22, w32)<br>\n","  X dot W + b >>> X가 앞에와야 맞는 계산이 됨<br>\n","  W를 앞으로 보내면 dot 계산시 다른 값 출력"],"metadata":{"id":"M7DEZveUKYFp"}}]}